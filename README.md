# ğŸ¤– RAG Chatbot

A powerful Retrieval-Augmented Generation (RAG) chatbot built with FastAPI backend and Streamlit frontend, powered by Google's Gemini 2.5 Flash model and ChromaDB vector database.

## âœ¨ Features

- ğŸ“„ **Document Upload**: Support for PDF, DOCX, and HTML files
- ğŸ’¬ **Interactive Chat Interface**: Real-time conversations with AI
- ğŸ” **RAG Implementation**: Retrieval-Augmented Generation for accurate, context-aware responses
- ğŸ—„ï¸ **Vector Database**: ChromaDB for efficient document storage and retrieval
- ğŸ“Š **Session Management**: Track conversation history across sessions
- ğŸ¯ **Model Selection**: Powered by Gemini 2.5 Flash
- ğŸ—‘ï¸ **Document Management**: Upload, list, and delete documents easily

## ğŸ—ï¸ Architecture

```
RAG Chatbot
â”œâ”€â”€ Backend (FastAPI)
â”‚   â”œâ”€â”€ Document Processing
â”‚   â”œâ”€â”€ Vector Database (ChromaDB)
â”‚   â”œâ”€â”€ RAG Chain (LangChain)
â”‚   â””â”€â”€ API Endpoints
â”‚
â””â”€â”€ Frontend (Streamlit)
    â”œâ”€â”€ Chat Interface
    â”œâ”€â”€ Document Upload
    â””â”€â”€ Session Management
```

## ğŸš€ Getting Started

### Prerequisites

- Python 3.8+
- Google Gemini API Key
- Git

### Installation

1. **Clone the repository**
```bash
git clone https://github.com/Tushar0852/RAG-Chatbot.git
cd RAG-Chatbot
```

2. **Set up virtual environment**
```bash
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate
```

3. **Install dependencies**
```bash
pip install -r requirements.txt
```

4. **Set up environment variables**

Create a `.env` file in the project root:
```env
GOOGLE_API_KEY=your_google_gemini_api_key_here
```

### Running the Application

#### Start the Backend (FastAPI)

```bash
# From the backend directory
uvicorn main:app --reload --port 8000
```

The backend API will be available at `http://localhost:8000`

#### Start the Frontend (Streamlit)

Open a new terminal and run:

```bash
# From the frontend directory
streamlit run streamlit_app.py
```

The Streamlit app will open automatically in your browser at `http://localhost:8501`

## ğŸ“ Project Structure

```
RAG-Chatbot/
â”œâ”€â”€ app/                          # Backend application
â”‚   â”œâ”€â”€ main.py                   # FastAPI application
â”‚   â”œâ”€â”€ langchain_utils.py        # RAG chain implementation
â”‚   â”œâ”€â”€ chroma_utils.py           # ChromaDB utilities
â”‚   â”œâ”€â”€ db_utils.py               # SQLite database utilities
â”‚   â”œâ”€â”€ pydantic_models.py        # Data models
â”‚   â””â”€â”€ chroma_db/                # Vector database storage
â”‚
â”œâ”€â”€ frontend/                     # Streamlit frontend
â”‚   â”œâ”€â”€ streamlit_app.py          # Main Streamlit app
â”‚   â”œâ”€â”€ sidebar.py                # Sidebar component
â”‚   â”œâ”€â”€ chat_interface.py         # Chat UI component
â”‚   â””â”€â”€ api_utils.py              # API communication
â”‚
â”œâ”€â”€ .env                          # Environment variables
â”œâ”€â”€ .gitignore                    # Git ignore file
â”œâ”€â”€ requirements.txt              # Python dependencies
â””â”€â”€ README.md                     # This file
```

## ğŸ”§ API Endpoints

### Backend API (Port 8000)

| Endpoint | Method | Description |
|----------|--------|-------------|
| `/chat` | POST | Send a query and get AI response |
| `/upload-doc` | POST | Upload a document (PDF/DOCX/HTML) |
| `/list-docs` | GET | List all uploaded documents |
| `/delete-doc` | POST | Delete a specific document |

### Example API Request

```python
import requests

# Chat endpoint
response = requests.post(
    "http://localhost:8000/chat",
    json={
        "question": "What is this document about?",
        "model": "gemini-2.5-flash",
        "session_id": "optional-session-id"
    }
)
```

## ğŸ› ï¸ Technologies Used

### Backend
- **FastAPI**: High-performance web framework
- **LangChain**: Framework for LLM applications
- **ChromaDB**: Vector database for document embeddings
- **Google Gemini 2.5 Flash**: Large Language Model
- **SQLite**: Session and log storage
- **PyPDF2**: PDF processing
- **python-docx**: DOCX processing
- **BeautifulSoup4**: HTML processing

### Frontend
- **Streamlit**: Interactive web application framework
- **Requests**: HTTP library for API calls

## ğŸ“ Usage Guide

### 1. Upload Documents
- Click on "Choose a file" in the sidebar
- Select a PDF, DOCX, or HTML file
- Click "Upload" button
- Wait for confirmation

### 2. Chat with Your Documents
- Type your question in the chat input
- The AI will retrieve relevant context from uploaded documents
- Get accurate, context-aware responses

### 3. Manage Documents
- View all uploaded documents in the sidebar
- Click "Refresh Document List" to update
- Select a document and click "Delete" to remove it

### 4. View Response Details
- Expand the "Details" section after each response
- See the generated answer, model used, and session ID

## ğŸ” Environment Variables

| Variable | Description | Required |
|----------|-------------|----------|
| `GOOGLE_API_KEY` | Your Google Gemini API key | Yes |

Get your API key from [Google AI Studio](https://makersuite.google.com/app/apikey)

## ğŸ¤ Contributing

Contributions are welcome! Please feel free to submit a Pull Request.

1. Fork the repository
2. Create your feature branch (`git checkout -b feature/AmazingFeature`)
3. Commit your changes (`git commit -m 'Add some AmazingFeature'`)
4. Push to the branch (`git push origin feature/AmazingFeature`)
5. Open a Pull Request

## ğŸ“„ License

This project is open source and available under the [MIT License](LICENSE).

## ğŸ‘¨â€ğŸ’» Author

**Tushar**
- GitHub: [@Tushar0852](https://github.com/Tushar0852)

## ğŸ™ Acknowledgments

- Google Gemini for the powerful LLM
- LangChain for the RAG framework
- ChromaDB for vector storage
- Streamlit for the amazing frontend framework

## ğŸ“§ Contact

For questions or feedback, please open an issue on GitHub.

---

â­ If you find this project useful, please consider giving it a star on GitHub!
